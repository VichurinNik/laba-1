\documentclass[12pt]{article}

\usepackage[english]{babel}
\usepackage{amsmath, amsfonts, amsthm}
\usepackage{graphicx}
\usepackage{float}
\usepackage{multicol}


\begin{document}

\section{Learning to Detect Roads}
\subsection{Unsupervised Pretraining}  

\raggedright Traditionally neural networks have been initialized with small random weights. However, it has recently been shown that using an unsupervised learning procedure to initialize the weights can significantly improve the performance of neural networks. Using such an initialization procedure has been referred to as pretraining.
\newline

\raggedright A  set  of  inclusion  and  exclusion  criteria  was  ascertained  as  competency  factors  to  identify  previous  studies  and  subjects  based  on  the  purpose  of  this  work.  The exclusion factors  were as follow.
\noindent

\begin{itemize}
    \item[-] The full text of the papers was not provided by publishers;
    \item[-] Remote sensing images were not used in the he papers;
    \item[-] Peer‐reviewed papers, such as conferences and journals;
    \item[-] Articles written in English;
\end{itemize}

\raggedright Although the methods utilized for road extraction used different data, this study can provide the following important outcomes 

\noindent
\begin{enumerate}
\item The capabilities of deep learning methods for road extraction are more effective than those of regular approaches
\item The low efficiency of the proposed methods in terms of data quality, training dataset, and model hyperparameters is presented Table(\ref{2})
\item Occlusions, such as shadows, cars, and buildings, are similar to road features, such as colors, reflectance, and patterns. Road extraction remains challenging owing to such issues Figure(\ref{1})
\end{enumerate}

\begin{figure}[H]
    \centering
    \includegraphics[width=100mm]{image.jpg}
    \caption{The pixel resolution of most }
    \label{1}
\end{figure}

\begin{table}[h!]
    \begin{center}
        \caption{The confusion matrix is a detailed}
        \label{2}
          \begin{tabular}{|p{3cm}|p{4cm}|p{4cm}|}
          \hline
           Year&Channel&Resolution\\
          \hline
          2017&N,R,G,B&15cm/px\\
          \hline
          2018&N,R,G,B&10cm/px\\
          \hline
          \end{tabular}
   \end{center}
\end{table}

\raggedright where Z is a normalizing constant and the energy E(v, h) 
formula(\ref{3}) is: \newline

\begin{equation}
\label{3}
E(V,h)=\sum_i V^2_i -\left( \sum_k b_k h_k + \sum_i w_i V_i h_k \right)
\end{equation}

\newpage

\raggedright In this work, we use Mean Squared Error (MSE) formula(\ref{4}) as the loss function:

\begin{equation}
\label{4}
\frac{1}{N}\sum^N_i V^2_i|| Net(I_i;W)-S_i||^2
\end{equation}

\raggedright where: N  –  is the number of the training samples,
\newline
 W  –  stochastic gradient descent.
 
 \subsection{Adding Rotations}
\raggedright When training the neural network f we found that it is useful to rotate each training case by a random angle each time it is processed. Since many cities have large areas where the road network forms a grid, training on data without rotations will result in a model that is better at detecting roads at certain orientations. By randomly rotating the training cases the resulting models do not favor roads in any particular orientation.
\newline
We propose a large-scale learning approach to road detection that addresses all three problems as follows
 \begin{itemize}
    \item[-] We use synthetic road/non-road labels that we generate from readily available vector road maps. This allows us to generate much larger labelled datasets than the ones that have been used in the past;
    \item[-]By using neural networks implemented on a graphics processor as our predictors we are able to efficiently learn a large number of features and use a large context for making predictions;
\end{itemize}

One major study of our work is the effectiveness of training multi-spectral data in image recognition.
\begin{enumerate}
\item We simultaneously investigate the impact of using models with different complexities Figure(\ref{5});
\item Aerial farmland images contain annotations with vastly different sizes;
\item In order to justify our choice of using 512 × 512 windows to construct the Agriculture-Vision dataset, we additionally generate two versions of the dataset with different window sizes;
\end{enumerate}

\begin{figure}
        \centering
        \includegraphics[width=100mm]{image2.jpg}
        \caption{The pixel resolution}
        \label{5}
    \end{figure}

\raggedright The dropout method operates on the fully connected layers to avoid overfitting because a fully connected layer usually contains a large number of parameters formula(\ref{6})

\begin{equation}
\label{6}
P(y_i)=\frac{e^Y_i}{\sum^c_i e^y_i}
\end{equation}

\end{document}